name: tyf
dataset: mysam/masael_chat
devices:
- 1
actions:
# loading full dataset
- id: load_dataset
  type: load_dataset
  split: test
  status: always

# training tokenizer or loading it if trained
- id: global_tokenizer
  type: train_load_tokenizer
  path: /home/jalalirs/Documents/code/arabi/maknaz/maknaz_/model/mysam/oryx-2.0-1B-Instruct-Llama
  kind: auto
  vocab_size: 128256
  status: always

# training tokenizer or loading it if trained
- id: llama_generator
  type: generate_chat_completion
  model_name: /home/jalalirs/Documents/code/arabi/maknaz/maknaz_/model/mysam/oryx-2.0-1B-Instruct-Llama
  file_name: data/generation_llama.jsonl
  tokenizer_id: global_tokenizer
  status: always
