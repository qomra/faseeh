name: mkatib
dataset: mysam/maajim
devices:
- 1
actions:
# loading full dataset
- id: load_dataset
  type: load_dataset
  status: always

# training tokenizer or loading it if trained
- id: global_tokenizer
  type: train_load_tokenizer
  path: /home/jalalirs/Documents/code/arabi/maknaz/maknaz_/model/mysam/oryx-2.0-1B-Base/
  kind: auto
  vocab_size: 32000
  status: always

# # pre_tokenizing the dataset
- id: pre_tokenize
  type: pre_tokenize_data
  path: dataset/maajim/
  tokenizer_id: global_tokenizer
  status: always
  block_size: 4096
  kind: hf


# pre-training a model based on the 10 samples dataset
- id: pre_trained
  type: pretrain
  path: /home/jalalirs/Documents/code/arabi/maknaz/maknaz_/model/mysam/oryx-2.0-1B-Base-Maajim/
  base_model_type: hf
  base_model_name: /home/jalalirs/Documents/code/arabi/maknaz/maknaz_/model/mysam/oryx-2.0-1B-Base/
  tokenizer_id: global_tokenizer
  status: done
